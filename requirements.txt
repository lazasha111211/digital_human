gradio==6.2.0
requests==2.32.5
python-multipart==0.0.21
ffmpeg-python==0.2.0
accelerate==1.8.1
cn2an==0.5.22
cython==3.0.7
descript-audiotools==0.7.2
einops>=0.8.1
g2p-en==2.1.0
jieba==0.42.1
json5==0.10.0
keras==2.9.0
librosa==0.10.2.post1
matplotlib==3.8.2
modelscope==1.27.0
munch==4.0.0
numba==0.58.1
numpy==1.26.2
omegaconf>=2.3.0
opencv-python==4.9.0.80
pandas==2.3.2
torchvision==0.23.0
safetensors==0.5.2
sentencepiece>=0.2.1
tensorboard==2.9.1
textstat>=0.7.10
tokenizers==0.21.0
torch==2.8.*
torchaudio==2.8.*
tqdm>=4.67.1
transformers==4.52.1
wetext>=0.0.9
deepspeed==0.18.3
#bitsandbytes==0.49.0  # 可选，用于模型量化（降低显存占用）
#flash-attn  FlashAttention 仅支持 NVIDIA GPU（算力 ≥ 7.0，如 V100/A100/3090/4090），不支持 CPU/AMD GPU/Apple Silicon（M 系列）。


# infinitetalk
diffusers>=0.31.0
imageio==2.37.2
easydict==1.13
dashscope==1.25.5
imageio-ffmpeg==0.6.0
scikit-image==0.25.2
loguru==0.7.3
xfuser>=0.4.1
optimum-quanto==0.2.6
scenedetect==0.6.7.1
moviepy==2.2.1
#decord
ftfy==6.2.0
# 适配transformer==4.52.1, 所有英伟达 GPU（CUDA 11.8+/12.x）;如果适配适配最新 CUDA 12.4+， 版本升级为 0.44.1
bitsandbytes==0.41.1  