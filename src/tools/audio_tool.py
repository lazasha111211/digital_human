import torch
import os
from transformers import WhisperProcessor, WhisperForConditionalGeneration

# åŠ è½½æœ¬åœ°Whisperæ¨¡åž‹ï¼ˆæ— librosa/resampyä¾èµ–ï¼‰
def load_local_whisper_transformers(
    model_dir: str,
    language: str = "Chinese",
    task: str = "transcribe"
):
    """
        åŠ è½½æœ¬åœ°Whisperæ¨¡åž‹(æ— librosa/resampyä¾èµ–)
    """
    # ç»å¯¹è·¯å¾„æ ¡éªŒï¼Œé¿å…ç›¸å¯¹è·¯å¾„é—®é¢˜
    # model_dir = os.path.abspath(model_dir)
    if not os.path.isdir(model_dir):
        raise FileNotFoundError(f"æœ¬åœ°æ¨¡åž‹æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼š{model_dir}")
    
    # æ ¸å¿ƒæ–‡ä»¶æ ¡éªŒï¼ˆæƒé‡äºŒé€‰ä¸€ï¼Œé…ç½®æ–‡ä»¶å¿…éœ€ï¼‰
    weight_files = ["pytorch_model.bin", "model.safetensors"]
    config_files = ["config.json", "preprocessor_config.json", "tokenizer.json"]
    weight_exists = any(os.path.exists(os.path.join(model_dir, f)) for f in weight_files)
    missing_config = [f for f in config_files if not os.path.exists(os.path.join(model_dir, f))]
    
    if not weight_exists:
        raise FileNotFoundError(f"ç¼ºå°‘æƒé‡æ–‡ä»¶ï¼ˆäºŒé€‰ä¸€ï¼‰ï¼š{weight_files}")
    if missing_config:
        raise FileNotFoundError(f"ç¼ºå°‘é…ç½®æ–‡ä»¶ï¼š{missing_config}")

    
    # å¢žå¼ºMPSæ£€æµ‹ï¼šåŒæ—¶æ ¡éªŒæ˜¯å¦å¯ç”¨+æ˜¯å¦ç¼–è¯‘æ”¯æŒï¼ˆé¿å…è¯¯åˆ¤ï¼‰
    if torch.cuda.is_available():
        device = "cuda"
        torch_dtype = torch.float16  # CUDAç”¨float16ï¼Œæé€Ÿ+é™æ˜¾å­˜
    elif torch.backends.mps.is_available() and torch.backends.mps.is_built():
        device = "mps"
        torch_dtype = torch.float16  # MPSæ”¯æŒfloat16ï¼Œæ€§èƒ½æ›´ä¼˜ï¼ˆä¹Ÿå¯ä¿ç•™float32ï¼Œç²¾åº¦æ›´é«˜ï¼‰
    else:
        device = "cpu"
        torch_dtype = torch.float32  # CPUç”¨float32ï¼Œç¨³å®šæ€§ä¼˜å…ˆ

    # å¢žå¼ºæ—¥å¿—ï¼šè¾“å‡ºè®¾å¤‡è¯¦æƒ…ï¼ˆå¦‚GPUåž‹å·/MPSæ ‡è¯†ï¼‰
    device_detail = torch.cuda.get_device_name(0) if device == "cuda" else "Apple Silicon" if device == "mps" else "x86/ARM CPU"
    print(f"ðŸ“Œ è¿è¡Œè®¾å¤‡ï¼š{device} ({device_detail}) | æ•°æ®ç±»åž‹ï¼š{torch_dtype}")

    # åŠ è½½æœ¬åœ°å¤„ç†å™¨ï¼ˆå¼ºåˆ¶ç¦»çº¿ï¼‰
    processor = WhisperProcessor.from_pretrained(
        model_dir,
        language=language,
        task=task,
        local_files_only=True  # ç¦æ­¢è”ç½‘ï¼Œä»…è¯»æœ¬åœ°æ–‡ä»¶
    )

    # åŠ è½½æœ¬åœ°æ¨¡åž‹ï¼ˆå¼ºåˆ¶ç¦»çº¿ï¼‰
    model = WhisperForConditionalGeneration.from_pretrained(
        model_dir,
        torch_dtype=torch_dtype,
        local_files_only=True,
        low_cpu_mem_usage=True  # å‡å°‘å†…å­˜å ç”¨
    ).to(device)

    # å¼ºåˆ¶ä¸­æ–‡è§£ç ï¼ˆå…³é”®ï¼šé¿å…è¯­è¨€è¯†åˆ«é”™è¯¯ï¼‰
    forced_decoder_ids = processor.get_decoder_prompt_ids(
        language=language,
        task=task
    )

    return processor, model, forced_decoder_ids, device

def transcribe_audio_to_chinese(
    audio_path: str,
    processor,
    model,
    forced_decoder_ids,
    device: str
) -> str:
    """æå–éŸ³é¢‘ä¸­çš„æ±‰å­—(çº¯transformerså®žçŽ°,æ— é¢å¤–ä¾èµ–ï¼‰"""
    # 1. æ ¡éªŒéŸ³é¢‘æ–‡ä»¶
    if not os.path.exists(audio_path):
        raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼š{audio_path}")

    # 2. æ ¸å¿ƒï¼šç”¨WhisperProcessorç›´æŽ¥åŠ è½½éŸ³é¢‘ï¼ˆè‡ªåŠ¨å¤„ç†é‡‡æ ·çŽ‡/å£°é“ï¼‰
    # æ— éœ€librosa/resampyï¼Œprocessorå†…ç½®FFmpegè§£ç é€»è¾‘
    print(f"ðŸ”Š é¢„å¤„ç†éŸ³é¢‘ï¼š{audio_path}")
    input_features = processor(
        audio=os.path.abspath(audio_path),          # ç›´æŽ¥ä¼ éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        sampling_rate=16000,       # Whisperå¼ºåˆ¶16kHz
        return_tensors="pt",       # è¿”å›žPyTorchå¼ é‡
        padding=True               # è‡ªåŠ¨å¡«å……
    ).input_features.to(device)   # ç§»åˆ°æŒ‡å®šè®¾å¤‡ï¼ˆGPU/CPUï¼‰ï¼Œ æ—¢æ”¯æŒ torch.device å¯¹è±¡ï¼Œä¹Ÿæ”¯æŒ å­—ç¬¦ä¸²ï¼ˆstrï¼‰

    # 3. æ¨¡åž‹æŽ¨ç†ï¼ˆä¼˜åŒ–ä¸­æ–‡å‚æ•°ï¼‰
    print("âš™ï¸ æ¨¡åž‹æŽ¨ç†ä¸­...")
    with torch.no_grad():  # æŽ¨ç†ç¦ç”¨æ¢¯åº¦è®¡ç®—
        predicted_ids = model.generate(
            input_features,
            forced_decoder_ids=forced_decoder_ids, # ä¸­æ–‡è½¬å†™æ ¸å¿ƒï¼šå¼ºåˆ¶æ¨¡åž‹è¾“å‡ºä¸­æ–‡ï¼ˆç¦ç”¨è‡ªåŠ¨æ£€æµ‹ï¼‰
            max_new_tokens=4096,       # é€‚é…é•¿éŸ³é¢‘ 4096 è¦†ç›–ç»å¤§å¤šæ•°é•¿è¯­éŸ³è½¬å†™éœ€æ±‚
            num_beams=5,               # æŸæœç´¢æå‡å‡†ç¡®çŽ‡ 5 = å¹³è¡¡å‡†ç¡®çŽ‡å’Œé€Ÿåº¦ï¼ˆä¸­æ–‡æŽ¨è 3-5ï¼‰
            temperature=0.0,           # 0=ç¡®å®šæ€§è¾“å‡ºï¼Œæ— éšæœºæ€§
            repetition_penalty=1.1,    # æŠ‘åˆ¶é‡å¤æ–‡æœ¬ è½»å¾®æƒ©ç½šï¼ˆä¸­æ–‡é¿å…è¿‡åº¦æˆªæ–­è¯­ä¹‰ï¼‰
            no_repeat_ngram_size=3     # ç¦æ­¢3å­—ä»¥ä¸Šé‡å¤
        )

    # 4. è§£ç ä¸ºæ±‰å­—ï¼ˆè·³è¿‡ç‰¹æ®Štokenï¼‰
    transcription = processor.batch_decode(
        predicted_ids,
        skip_special_tokens=True
    )[0].strip()

    return transcription

def transcribe(model_dir: str,
    audio_dir: str,
    language: str = "Chinese",
    task: str = "transcribe"
) -> str: 
    
    processor, model, forced_decoder_ids, device = load_local_whisper_transformers(
        model_dir=model_dir,
        language="Chinese"
    )

    transcription = transcribe_audio_to_chinese(
            audio_path=audio_dir,
            processor=processor,
            model=model,
            forced_decoder_ids=forced_decoder_ids,
            device=device
        )
    return transcription

